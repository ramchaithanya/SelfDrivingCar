{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import datetime\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_loc = './Data/data/IMG/'\n",
    "csv_file_loc = './Data/data/driving_log.csv'\n",
    "data_loc = './Data/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "data_df = pd.read_csv('./Data/data/driving_log.csv', names=['center', 'left', 'right', 'steering', 'throttle', 'reverse', 'speed'])\n",
    "\n",
    "X = data_df[['center', 'left', 'right']].values\n",
    "y = data_df['steering'].values\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2, os\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "\n",
    "#IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS = 66, 200, 3\n",
    "IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS = 64, 64, 3\n",
    "INPUT_SHAPE = (IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS)\n",
    "\n",
    "\n",
    "def load_image(data_dir, image_file):\n",
    "    \"\"\"\n",
    "    Load RGB images from a file\n",
    "    \"\"\"\n",
    "    return mpimg.imread(os.path.join(data_dir, image_file.strip()))\n",
    "\n",
    "\n",
    "def crop(image):\n",
    "    \"\"\"\n",
    "    Crop the image (removing the sky at the top and the car front at the bottom)\n",
    "    \"\"\"\n",
    "    return image[60:-25, :, :] # remove the sky and the car front\n",
    "\n",
    "\n",
    "def resize(image):\n",
    "    \"\"\"\n",
    "    Resize the image to the input shape used by the network model\n",
    "    \"\"\"\n",
    "    return cv2.resize(image, (IMAGE_WIDTH, IMAGE_HEIGHT), cv2.INTER_AREA)\n",
    "\n",
    "\n",
    "def rgb2yuv(image):\n",
    "    \"\"\"\n",
    "    Convert the image from RGB to YUV (This is what the NVIDIA model does)\n",
    "    \"\"\"\n",
    "    return cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n",
    "\n",
    "\n",
    "def preprocess(image):\n",
    "    \"\"\"\n",
    "    Combine all preprocess functions into one\n",
    "    \"\"\"\n",
    "    image = crop(image)\n",
    "    image = resize(image)\n",
    "    image = rgb2yuv(image)\n",
    "    return image\n",
    "\n",
    "\n",
    "def choose_image(data_dir, center, left, right, steering_angle):\n",
    "    \"\"\"\n",
    "    Randomly choose an image from the center, left or right, and adjust\n",
    "    the steering angle.\n",
    "    \"\"\"\n",
    "    choice = np.random.choice(3)\n",
    "    if str(steering_angle) == False:\n",
    "        if choice == 0:\n",
    "            return load_image(data_dir, left), steering_angle + 0.2\n",
    "        elif choice == 1:\n",
    "            return load_image(data_dir, right), steering_angle - 0.2\n",
    "    return load_image(data_dir, center), steering_angle\n",
    "\n",
    "\n",
    "def random_flip(image, steering_angle):\n",
    "    \"\"\"\n",
    "    Randomly flipt the image left <-> right, and adjust the steering angle.\n",
    "    \"\"\"\n",
    "    if np.random.rand() < 0.5:\n",
    "        image = cv2.flip(image, 1)\n",
    "        random_flip = -float(steering_angle)\n",
    "        return image,random_flip\n",
    "    return image, steering_angle\n",
    "\n",
    "\n",
    "def random_translate(image, steering_angle, range_x, range_y):\n",
    "    \"\"\"\n",
    "    Randomly shift the image virtially and horizontally (translation).\n",
    "    \"\"\"\n",
    "    trans_x = range_x * (np.random.rand() - 0.5)\n",
    "    trans_y = range_y * (np.random.rand() - 0.5)\n",
    "    #print('Hi '+steering_angle)\n",
    "    steering_angle += trans_x * 0.002\n",
    "    trans_m = np.float32([[1, 0, trans_x], [0, 1, trans_y]])\n",
    "    height, width = image.shape[:2]\n",
    "    image = cv2.warpAffine(image, trans_m, (width, height))\n",
    "    return image, steering_angle\n",
    "\n",
    "\n",
    "def random_shadow(image):\n",
    "    \"\"\"\n",
    "    Generates and adds random shadow\n",
    "    \"\"\"\n",
    "    # (x1, y1) and (x2, y2) forms a line\n",
    "    # xm, ym gives all the locations of the image\n",
    "    x1, y1 = IMAGE_WIDTH * np.random.rand(), 0\n",
    "    x2, y2 = IMAGE_WIDTH * np.random.rand(), IMAGE_HEIGHT\n",
    "    xm, ym = np.mgrid[0:IMAGE_HEIGHT, 0:IMAGE_WIDTH]\n",
    "\n",
    "    # mathematically speaking, we want to set 1 below the line and zero otherwise\n",
    "    # Our coordinate is up side down.  So, the above the line: \n",
    "    # (ym-y1)/(xm-x1) > (y2-y1)/(x2-x1)\n",
    "    # as x2 == x1 causes zero-division problem, we'll write it in the below form:\n",
    "    # (ym-y1)*(x2-x1) - (y2-y1)*(xm-x1) > 0\n",
    "    mask = np.zeros_like(image[:, :, 1])\n",
    "    mask[(ym - y1) * (x2 - x1) - (y2 - y1) * (xm - x1) > 0] = 1\n",
    "\n",
    "    # choose which side should have shadow and adjust saturation\n",
    "    cond = mask == np.random.randint(2)\n",
    "    s_ratio = np.random.uniform(low=0.2, high=0.5)\n",
    "\n",
    "    # adjust Saturation in HLS(Hue, Light, Saturation)\n",
    "    hls = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "    hls[:, :, 1][cond] = hls[:, :, 1][cond] * s_ratio\n",
    "    return cv2.cvtColor(hls, cv2.COLOR_HLS2RGB)\n",
    "\n",
    "\n",
    "def random_brightness(image):\n",
    "    \"\"\"\n",
    "    Randomly adjust brightness of the image.\n",
    "    \"\"\"\n",
    "    # HSV (Hue, Saturation, Value) is also called HSB ('B' for Brightness).\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    ratio = 1.0 + 0.4 * (np.random.rand() - 0.5)\n",
    "    hsv[:,:,2] =  hsv[:,:,2] * ratio\n",
    "    return cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
    "\n",
    "\n",
    "def augument(data_dir, center, left, right, steering_angle, range_x=100, range_y=10):\n",
    "    \"\"\"\n",
    "    Generate an augumented image and adjust steering angle.\n",
    "    (The steering angle is associated with the center image)\n",
    "    \"\"\"\n",
    "    image, steering_angle = choose_image(data_dir, center, left, right, steering_angle)\n",
    "    image, steering_angle = random_flip(image, steering_angle)\n",
    "    image, steering_angle = random_translate(image, steering_angle, range_x, range_y)\n",
    "    #image = random_shadow(image)\n",
    "    image = random_brightness(image)\n",
    "    return image, steering_angle\n",
    "\n",
    "\n",
    "def batch_generator(data_dir, image_paths, steering_angles, batch_size, is_training):\n",
    "    \"\"\"\n",
    "    Generate training image give image paths and associated steering angles\n",
    "    \"\"\"\n",
    "    images = np.empty([batch_size, IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS])\n",
    "    steers = np.empty(batch_size)\n",
    "    while True:\n",
    "        i = 0\n",
    "        for index in np.random.permutation(image_paths.shape[0]):\n",
    "            center, left, right = image_paths[index]\n",
    "            steering_angle = steering_angles[index]\n",
    "            if steering_angle == 'steering':\n",
    "                continue\n",
    "            if center == 'center':\n",
    "                continue\n",
    "            steering_angle = float(steering_angle)\n",
    "            if is_training and np.random.rand() < 0.6:\n",
    "                image, steering_angle = augument(data_dir, center, left, right, steering_angle)\n",
    "            else:\n",
    "                image = load_image(data_dir, center) \n",
    "            # add the image and steering angle to the batch\n",
    "            #print(image.shape)\n",
    "            images[i] = preprocess(image)\n",
    "            steers[i] = float(steering_angle)\n",
    "            i += 1\n",
    "            if i == batch_size:\n",
    "                break\n",
    "        yield images, steers\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.layers.core import Flatten, Dense, Lambda\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Convolution2D, ELU,Conv2D,MaxPooling2D\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import model_from_json\n",
    "from keras.layers.convolutional import Cropping2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda (Lambda)              (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 30, 30, 24)        1824      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 13, 13, 36)        21636     \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 5, 5, 48)          43248     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 3, 64)          27712     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 1, 1, 64)          36928     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1164)              75660     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               116500    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 329,079\n",
      "Trainable params: 329,079\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Lambda(lambda image: image / 127.5 - 1., input_shape=(IMAGE_HEIGHT,IMAGE_WIDTH,3)))\n",
    "model.add(Conv2D(24, (5, 5), strides=(2, 2), activation=\"elu\"))\n",
    "model.add(Conv2D(36, (5, 5), strides=(2, 2), activation=\"elu\"))\n",
    "model.add(Conv2D(48, (5, 5), strides=(2, 2), activation=\"elu\"))\n",
    "model.add(Conv2D(64, (3, 3), activation=\"elu\"))\n",
    "model.add(Conv2D(64, (3, 3), activation=\"elu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1164))\n",
    "model.add(Dense(100))\n",
    "model.add(Dense(50))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(1))\n",
    "model.summary()\n",
    "optimizer = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(optimizer=optimizer, loss='mse',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6429\n",
      "Epoch 1/3\n",
      "   36/25716 [..............................] - ETA: 58:26 - loss: 0.0159 - accuracy: 0.2214"
     ]
    }
   ],
   "source": [
    "print(X_train.shape[0])\n",
    "model.fit(batch_generator(data_loc, X_train, y_train, 32,True),\n",
    "                        steps_per_epoch = len(X_train)*4,\n",
    "                        epochs = 3,\n",
    "                        shuffle = True,\n",
    "                        validation_data=batch_generator(data_loc, X_valid, y_valid, 32, False),\n",
    "                        validation_steps=len(X_valid),\n",
    "                        verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
